## Пакетный конвертер аудио и видео файлов в текст с восстановлением пунктуации и регистра для русского языка

**Вход**: аудио/видео-файл(ы)

**Выход**: текст + текст с таймкодами (опционально)

## Описание

Этот скрипт использует модель Whisper от OpenAI или модели Hugging Face для преобразования речи в текст и модель SBert для восстановления пунктуации и регистра в русском языке. Поддерживает следующие форматы: mp3, aac, wav, ogg, m4a, mp4, opus, mov, avi, mkv, webm.

Желательно использовать GPU (дискретную видеокарту), но на CPU тоже работает (медленно).

## Ограничения

- Для работы с GPU требуется установленный драйвер CUDA
- Качество распознавания зависит от выбранной модели (чем больше модель, тем лучше результат и тем медленнее выполняется распознавание)
- Восстановление пунктуации и регистра работает только для русского языка

## Подготовка

1. Установите [Python](https://python.org) 3.10+

2. Установите PyTorch
- с поддержкой CUDA (если планируете использовать GPU). Например, для версии CUDA 12.6:
`pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126`
Подробности установки других версий можно уточнить тут: https://pytorch.org/

   Чтобы узнать, какая версия CUDA установлена на компьютере, в Windows откройте консоль (Win+R, cmd) и запустите `nvidia-smi`. В начале отчёта будет указана версия CUDA.

- без поддержки CUDA (если на компьютере нет дискретной видеокарты или не требуется использовать CUDA): `pip install torch`

3. Установите библиотеки [Whisper](https://github.com/openai/whisper) и transformers: `pip install openai-whisper transformers`

4. Установите скомпилированный [FFMPEG](https://ffmpeg.org/download.html) и добавьте путь к `ffmpeg.exe` в переменную окружения `path`

## Использование

1. Запустите скрипт. Если все зависимости установлены, из Интернета загрузятся модели (только при первом запуске) и начнется распознавание указанного файла или папки.
2. По ходу работы программы отображается пргресс распознавания.
3. По завершении работы программы рядом с каждым исходным файлом появятся два текстовых файла:
   - filename.txt - распознанный текст, по одному предложению в строке.
   - filename_timecode.txt - распознанный текст с таймкодами, по ~3-5 секунд в строке.

### Параметры командной строки

- `-i`, `--input`: имя исходного медиафайла для конвертации в текст
- `-f`, `--folder`: папка с медиафайлами для обработки (по умолчанию - текущая папка)
- `-d`, `--device`: устройство для запуска модели (`cpu` или `cuda`, по умолчанию `cpu`)
- `-m`, `--model`: модель Whisper (`tiny`, `base`, `small`, `medium`, `large-v3`, `large-v3-turbo`) или путь к модели Hugging Face, по умолчанию `large-v3-turbo`)
- `-l`, `--language`: принудительное распознавание на указанном языке (например, `ru`). Если не задать, язык определяется автоматически
- `-r`, `--raw`: отключить исправление пунктуации и регистра (по умолчанию исправление включено)
- `-t`, `--timecode`: включить дополнительный файл с таймкодами и текстом (по умолчанию отключено)

### Простой вариант с настройками по умолчанию

`python batch-speech-to-text.py -i record.mp3`

### Расширенный вариант с параметрами

`python batch-speech-to-text.py -f d:\ASR -m medium -d cuda -l ru`

где:
- `-f d:\ASR` - папка с медиафайлами для обработки
- `-m medium` - использовать модель Whisper `medium`
- `-d cuda` - использовать GPU для ускорения распознавания
- `-l ru` - принудительно использовать русский язык для распознавания

### Использование моделей Hugging Face

Вы можете использовать любую модель Hugging Face, указав её путь:

`python batch-speech-to-text.py -i record.mp3 -m dvislobokov/whisper-large-v3-turbo-russian`

## Credits

- [OpenAI Whisper](https://github.com/openai/whisper)
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index)
- [SBert Punctuation and Case Model](https://huggingface.co/kontur-ai/sbert_punc_case_ru)